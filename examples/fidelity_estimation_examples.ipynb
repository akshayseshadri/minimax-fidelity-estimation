{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fidelity estimation: Minimax Method\n",
    "We show how to use the code for minimax method using some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Cluster state and Pauli measurements\n",
    "To demonstrate how to use the minimax method to estimate fidelity, we consider a 3-qubit linear cluster state as our target state.\\\n",
    "We will focus on Pauli measurements.\n",
    "\n",
    "The minimax method constructs an estimator when the target state, the measurement settings, and the confidence level is specified. One we construct the estimator, we can repeatedly reuse the estimator for the chosen settings.\n",
    "\n",
    "We outline the basic steps that we will go through in this example - from specifying the settings to computing the estimate.\n",
    "1. Create a YAML file describing the settings required to construct the estimator.\n",
    "2. Construct the estimator using the specified settings.\n",
    "3. Create a CSV file containing the measurement outcomes.\n",
    "4. Compute the fidelity estimate using the CSV file and the constructed estimator.\n",
    "\n",
    "We remark that step 2 is usually computation intensive. Nevertheless, once the estimator has been constructed, the fidelity estimates (step 4) can be obtained almost instantaneously.\n",
    "\n",
    "Let's look at each step in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a YAML file with the measurement settings.\n",
    "[YAML](https://en.wikipedia.org/wiki/YAML) is a markup language that is human-readable, and can be parsed by a computer. The combination of these attributes makes it a good medium to specify the settings to the code.\n",
    "\n",
    "We allow for different ways to specify the settings in the YAML file.\\\n",
    "For example, one could specify the target state as a list in the YAML file, or provide a path to a `.npy` file containing the numpy array for the target state.\\\n",
    "Since Pauli measurements and some special states like the stabilizer states are commonly used, we have provided a special interface to conveniently specify these settings.\\\n",
    "We will be using the latter interface in this demo for convenience. For details on all available formats to specify the settings, we encourage the reader to refer to the documentation of the code.\n",
    "\n",
    "We create the following settings file for the cluster state. We specify those Pauli operators $P$ that have a non-zero weight $\\text{Tr}(P \\rho)$.\n",
    "\n",
    "-------------------------------------------------\n",
    "### cluster_state_settings.yaml\n",
    "```\n",
    "target:\n",
    "    - cluster: 3\n",
    "POVM_list:\n",
    "    - pauli: [IZX, XIX, XZI, YXY, YYZ, ZXZ, ZYY]\n",
    "R_list: 100\n",
    "confidence_level: 0.95\n",
    "```\n",
    "-------------------------------------------------\n",
    "\n",
    "Let's take a closer look at the settings.\n",
    "- `target` refers to the target state. We can conveniently provide a linear cluster state using the syntax: `- cluster: nq`, where `nq` is the number of qubits.\\\n",
    "  We have therefore specified a 3-qubit cluster state.\n",
    "  \n",
    "- `POVM_list` is a list of POVMs that will measured in order to estimate the fidelity.\\\n",
    "  Pauli measurements can be specified in a few different ways, but here we use the most obvious one: list the Pauli operators that you want to measure.\\\n",
    "  The default measurement is projection on each eigenvector of the Pauli operator, but if collective measurement on eigenspace with $+1$ and $-1$ eigenvalue is required, you can include the keyword `subspace` after listing all the Pauli operators.\n",
    "\n",
    "- `R_list` corresponds to the number of outcomes recorded for each POVM.\\\n",
    "    We want 100 outcomes for each Pauli measurement, so we simply write 100.\\\n",
    "    If something more specific is required, write a list of outcomes, one for each Pauli measurement.\n",
    "\n",
    "- `confidence_level` should be a number between 0.75 and 1, and it determines the confidence level of the computed risk.\n",
    "\n",
    "----------\n",
    "> **It is important to adhere to the syntax specified in the documentation when creating the YAML file.**\\\n",
    "The code is expected to throw an error when incorrect syntax is used. However, there could be some cases that slip past the sanity checks, and the code may end up constructing an estimator that was not intended by the user!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Construct the estimator\n",
    "In order to construct the estimator, we use the function ```construct_fidelity_estimator``` included in ```handle_fidelity_estimation.py``` module.\n",
    "\n",
    "The syntax for this function is pretty straightforward:\n",
    "\n",
    "----------------------\n",
    "```\n",
    "construct_fidelity_estimator(yaml_filename, estimator_filename,\n",
    "                             yaml_file_dir = './yaml_files', estimator_dir = './estimator_files')\n",
    "```\n",
    "----------------------\n",
    "\n",
    "A closer look at the options:\n",
    "- ```yaml_filename``` refers to the name of the YAML settings file.\n",
    "- ```estimator_filename``` refers to the name of the (JSON) file to which the constructed estimator is saved.\n",
    "- ```yaml_file_dir``` specifies the directory in which the YAML settings file is stored.\\\n",
    "  This is an optional argument, and if nothing is specified, the code assumes that the YAML file lives in a sub-directory named `yaml_files` of the current directory.\n",
    "- ```estimator_dir``` specifies the directory where the constructed estimator is saved.\\\n",
    "  As before, this is an optional argument, and the default location is assumed to be a sub-directory named `estimator_files` of the current directory.\n",
    "\n",
    "------------------\n",
    "\n",
    "> We save the estimator because the same estimator can be re-used later for the same settings.\\\n",
    "The estimator is saved as a JSON file. These files are internally handled by the functions in the module, and need not be edited manually by the user.\n",
    "\n",
    "------------------\n",
    "\n",
    "Following the default options, we have created a subdirectory called `yaml_files` and placed `cluster_state_settings.yaml` YAML file there. Let us now construct the estimator. \n",
    "\n",
    "> **It can take anywhere from a few minutes to many hours to compute the estimator depending on the settings that were specified.**\\\n",
    "  If the dimension of the system is large or many measurement settings are begin used, please consider running the code on a workstation or a cluster.\n",
    "  \n",
    "The following code is expected to run in about 4 minutes on a laptop, though the actual time may vary depending on the hardware and the OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Fidelity_Estimation_Manager_CVXPY' object has no attribute 'nq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mproject_root\u001b[39;00m \u001b[39m# adds the root directory of the project to Python Path\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhandle_fidelity_estimation\u001b[39;00m \u001b[39mimport\u001b[39;00m construct_fidelity_estimator\n\u001b[1;32m----> 4\u001b[0m construct_fidelity_estimator(yaml_filename \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mcluster_state_settings.yaml\u001b[39;49m\u001b[39m'\u001b[39;49m,\\\n\u001b[0;32m      5\u001b[0m                              estimator_filename \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mcluster_state_estimator.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32me:\\Code\\repos\\minimax-fidelity-estimation\\handle_fidelity_estimation.py:465\u001b[0m, in \u001b[0;36mconstruct_fidelity_estimator\u001b[1;34m(yaml_filename, estimator_filename, yaml_file_dir, estimator_dir, print_progress)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     \u001b[39m# construct the fidelity estimator for specified target state and measurement settings\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     FEM \u001b[39m=\u001b[39m Fidelity_Estimation_Manager_CVXPY(R_list, epsilon, rho, POVM_list, epsilon_o, tol, random_init, print_progress)\n\u001b[1;32m--> 465\u001b[0m     _, risk \u001b[39m=\u001b[39m FEM\u001b[39m.\u001b[39;49mfind_fidelity_estimator()\n\u001b[0;32m    466\u001b[0m     phi_opt_list \u001b[39m=\u001b[39m FEM\u001b[39m.\u001b[39mphi_opt_list\n\u001b[0;32m    467\u001b[0m     c \u001b[39m=\u001b[39m FEM\u001b[39m.\u001b[39mc\n",
      "File \u001b[1;32me:\\Code\\repos\\minimax-fidelity-estimation\\src\\fidelity_estimation_cvxpy.py:295\u001b[0m, in \u001b[0;36mfind_fidelity_estimator\u001b[1;34m(self, solver)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_fidelity_estimator\u001b[39m(\u001b[39mself\u001b[39m, solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSCS\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    274\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39m        Constructs an estimator for fidelity between a pure state rho and an unknown state sigma.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \n\u001b[0;32m    277\u001b[0m \u001b[39m        First, the saddle point sigma_1*, sigma_2*, phi*, alpha* of the function\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[0;32m    279\u001b[0m \u001b[39m        \\Phi_r(sigma_1, sigma_2; phi, alpha) = Tr(rho sigma_1) - Tr(rho sigma_2)\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[39m                                                + \\sum_{i = 1}^N alpha R_i log(\\sum_{k = 1}^{N_i} exp(-phi^{i}_k/alpha) (p^{i}_1)_k)\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[39m                                                    + \\sum_{i = 1}^N alpha R_i log(\\sum_{k = 1}^{N_i} exp(phi^{i}_k/alpha) (p^{i}_2)_k)\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[39m                                                        + 2 alpha r\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \n\u001b[0;32m    284\u001b[0m \u001b[39m        is found. Here,\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[39m        (p^{i}_1)_k = (Tr(E^(i)_k sigma_1) + \\epsilon_o/Nm) / (1 + \\epsilon_o) and\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39m        (p^{i}_2)_k = (Tr(E^{i}_k sigma_2) + \\epsilon_o/Nm) / (1 + \\epsilon_o)\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[39m        are the probability distributions corresponding to the ith POVM {E^{i}_k}_{k = 1}^{N_i} with N_i elements.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m        R_i > 0 is a parameter that denotes the number of observations of the ith type of measurement (i.e., ith POVM).\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m        There are a total of N POVMs.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \n\u001b[0;32m    291\u001b[0m \u001b[39m        Then, an estimator is constructed as follows.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \n\u001b[0;32m    293\u001b[0m \u001b[39m        \\hat{F}(\\omega^{1}_1, ..., \\omega^{1}_{R_1}, ..., \\omega^{N}_1, ..., \\omega^{N}_{R_N})\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[39m                = \\sum_{i = 1}^N \\sum_{l = 1}^{R_i} phi*(\\omega^{i}_l) + c\u001b[39;00m\n\u001b[1;32m--> 295\u001b[0m \n\u001b[0;32m    296\u001b[0m \u001b[39m        where the constant 'c' is given by the optimization problem\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \n\u001b[0;32m    298\u001b[0m \u001b[39m        c = 0.5 \\max_{sigma_1} [Tr(rho sigma_1) + \\sum_{i = 1}^N alpha* R_i log(\\sum_{k = 1}^{N_i} exp(-phi*^{i}_k/alpha*) (p^{i}_1)_k)]\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[39m             - 0.5 \\max_{sigma_2} [-Tr(rho sigma_2) + \\sum_{i = 1}^N alpha* R_i log(\\sum_{k = 1}^{N_i} exp(phi*^{i}_k/alpha*) (p^{i}_2)_k)]\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \n\u001b[0;32m    301\u001b[0m \u001b[39m        We use the convention that the ith POVM outcomes are labelled as \\Omega_i = {0, ..., N_m - 1}, as Python is zero-indexed.\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[39m# find x, y, and alpha components of the saddle point\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     sigma_1_opt, sigma_2_opt, alpha_opt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaximize_risk_density_matrices(solver\u001b[39m=\u001b[39msolver)\n",
      "File \u001b[1;32me:\\Code\\repos\\minimax-fidelity-estimation\\src\\fidelity_estimation_cvxpy.py:245\u001b[0m, in \u001b[0;36mmaximize_risk_density_matrices\u001b[1;34m(self, R_list, solver)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmaximize_risk_density_matrices\u001b[39m( \u001b[39mself\u001b[39m, R_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSCS\u001b[39m\u001b[39m'\u001b[39m ):\n\u001b[0;32m    224\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39m        Solves the convex optimization problem with cvxpy. \u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[39m        The solver SCS is packaged with cvxpy, but problem is compatible with MOSEK,\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39m        which may be faster in practice. \u001b[39;00m\n\u001b[0;32m    228\u001b[0m \n\u001b[0;32m    229\u001b[0m \u001b[39m        \\max_{x, y \\in X} <rho, x - y>\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \n\u001b[0;32m    231\u001b[0m \u001b[39m        \\subject to ln( AffH( A(x), A(y) ) ) >= ln( epsilon / 2 )\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \n\u001b[0;32m    233\u001b[0m \u001b[39m        The function ln( AffH( A(x), A(y) ) ) is given as\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \n\u001b[0;32m    235\u001b[0m \u001b[39m        ln( AffH( A(x), A(y) ) = \\sum_{i = 1}^N R_i log(\\sum_{k = 1}^{N_i} \\sqrt{(p^{i}_1)_k (p^{i}_2)_k})]\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39m        where\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39m        (p^{i}_1)_k = (Tr(E^(i)_k sigma_1) + \\epsilon_o/Nm) / (1 + \\epsilon_o) and\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m        (p^{i}_2)_k = (Tr(E^{i}_k sigma_2) + \\epsilon_o/Nm) / (1 + \\epsilon_o) \u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m        are the probability distributions corresponding to the ith POVM {E^{i}_k}_{k = 1}^{N_i} with N_i elements.\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m        \u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[39m        R_i > 0 is a parameter that denotes the number of observations of the ith type of measurement (i.e., ith POVM).\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[39m        There are a total of N POVMs.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[0;32m    244\u001b[0m \u001b[39m        In relation to the saddle point problem, the optimal dual variable of our constraint is equivalent to alpha*\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m     \u001b[39m# Only need to compile the problem once\u001b[39;00m\n\u001b[0;32m    248\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcvxpy_prob \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Code\\repos\\minimax-fidelity-estimation\\src\\fidelity_estimation_cvxpy.py:187\u001b[0m, in \u001b[0;36mdefine_cvxpy_problem\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefine_cvxpy_problem\u001b[39m( \u001b[39mself\u001b[39m ):\n\u001b[0;32m    180\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[39m    Defines/compiles the convex optimization problem with cvxpy\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[39m        \\max_{x, y \\in X} <rho, x - y>\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \n\u001b[0;32m    185\u001b[0m \u001b[39m        \\subject to ln( AffH( A(x), A(y) ) ) >= ln( epsilon / 2 )\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \n\u001b[1;32m--> 187\u001b[0m \u001b[39m    This only needs to be done once, and can then be called multiple times \u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     \u001b[39m# Define variables\u001b[39;00m\n\u001b[0;32m    191\u001b[0m     x \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39mVariable((\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnq, \u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnq), hermitian\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Fidelity_Estimation_Manager_CVXPY' object has no attribute 'nq'"
     ]
    }
   ],
   "source": [
    "import project_root # adds the root directory of the project to Python Path\n",
    "from handle_fidelity_estimation import construct_fidelity_estimator\n",
    "\n",
    "construct_fidelity_estimator(yaml_filename = 'cluster_state_settings.yaml',\\\n",
    "                             estimator_filename = 'cluster_state_estimator.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Note that `construct_fidelity_estimator` prints the progress of optimization by default.\\\n",
    "     If you wish to turn this off, supply `print_progress = False` as an additional argument to the function.\n",
    "2. If an estimator file already exists, `construct_fidelity_estimator` function will throw an error. You can delete the existing estimator, move it to a different directory, or use another name to save the estimator in that case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate measurement outcomes\n",
    "We generate the measurement outcomes separately and store them in a CSV file.\\\n",
    "Note that these outcomes are generated using the state obtained by applying 10% depolarizing noise to the target state.\n",
    "\n",
    "> In practice, these outcomes will come from experiments.\n",
    "\n",
    "The CSV file looks as follows:\n",
    "\n",
    "---------------------\n",
    "### cluster_state_outcomes.csv\n",
    "\n",
    "|     |   |   |     |   |\n",
    "| --- | - | - | --- | - |\n",
    "| IZX | 7 | 0 | ... | 7 |\n",
    "| XIX | 7 | 7 | ... | 0 |\n",
    "|  .  | . | . |  .  | . |\n",
    "| ZYY | 5 | 3 | ... | 0 |\n",
    "\n",
    "---------------------\n",
    "The first column contains the labels of the Pauli measurements performed.\\\n",
    "Corresponding to each Pauli operator, we store the measurement outcomes in the same row as the Pauli operator.\\\n",
    "Outcome $i$ points to the eigenvector $\\vert i \\rangle$ that was observed upon measurement.\n",
    "\n",
    "> 1. **It is important that the order of eigenvectors used for outcomes matches the POVM that was specified for constructing the estimator.**\\\n",
    "  We use the following convention for the eigenvectors: $\\vert+++\\rangle$, $\\vert++-\\rangle$, $\\vert+-+\\rangle$, ..., $\\vert---\\rangle$.\\\n",
    "  Basically, we use the binary expansion of numbers from $0$ to $2^{n_q} - 1$, where $n_q$ are the number of qubits, with $0$ replaced by $+$ and $1$ replaced by $-$.\n",
    "2. **It is important that the outcomes for Pauli operators are listed in the same order as what we used for constructing the estimator.**\\\n",
    "   That is, we must have outcomes for IZXZ, XIX, ..., ZYY in that order in the CSV file.\n",
    "  \n",
    "Note for any Pauli operator $P = X_1 \\dotsb X_{n_q}$, a $+$ at the $i$th qubit location means that we are looking at the $+1$ eigenvector of $X_i$, where $X_i \\in \\{I, X, Y, Z\\}$.\n",
    "\n",
    "> In practice, steps 2 & 3 can occur in any order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compute the fidelity estimate\n",
    "Let's use the estimator that we constructed in step 2 and the outcomes generated in step 3 to compute the fidelity estimate.\\\n",
    "This task is handled by `compute_fidelity_estimate_risk` function in `handle_fidelity_estimation.py` module.\n",
    "\n",
    "This function takes the following form.\n",
    "\n",
    "----------------\n",
    "```\n",
    "compute_fidelity_estimate_risk(outcomes, estimator_filename, estimator_dir = './estimator_files')\n",
    "```\n",
    "----------------\n",
    "\n",
    "The options accept the following formats:\n",
    "- `outcomes` can be one of the following:\n",
    "    1. A list of outcomes for each POVM measurement.\n",
    "    2. Path to a YAML file containing a list of outcomes for each POVM measurement.\n",
    "    3. - Path to a CSV file, or\n",
    "       - A dictionary:\\\n",
    "           `{'csv_file_path': Path to CSV file, 'entries': 'row'/'column', 'start': (row index, column index)}`\\\n",
    "         where `row` (`column`) is used if data is stored in rows (columns),\\\n",
    "         and `start` denotes the index of the cell where the data starts (we start the row and column at index 0).\n",
    "- `estimator_filename` is the name of the estimator file that we constructed previously.\n",
    "- `estimator_dir` refers to the directory in which the estimator file has been saved.\n",
    "\n",
    "We refer the reader to the documentation of the code which elaborates these options further.\n",
    "\n",
    "As we can see from the CSV file outline in step 3, the data starts at the first row and the second column.\\\n",
    "The first column describes the data, but is not actually a part of it. Therefore, we set `start = (0, 1)`.\\\n",
    "As noted earlier, we label the rows and columns starting from 0, following Python convention.\\\n",
    "Also, it is clear that the data is stored row-wise, so we set `entries = 'row'`.\n",
    "\n",
    "Note that we have saved the `cluster_state_outcomes.csv` file in a subdirectory called `outcome_files`.\\\n",
    "Using this, we compute the estimate as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity estimate: 0.925\n",
      "Risk: 0.086\n"
     ]
    }
   ],
   "source": [
    "import project_root # adds the root directory of the project to Python Path\n",
    "from handle_fidelity_estimation import compute_fidelity_estimate_risk\n",
    "\n",
    "compute_fidelity_estimate_risk(outcomes = {'csv_file_path': './outcome_files/cluster_state_outcomes.csv',\\\n",
    "                                           'entries': 'row', 'start': (0, 1)},\\\n",
    "                               estimator_filename = 'cluster_state_estimator.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the estimate $\\widehat{F} \\approx 0.925$ is close to the actual fidelity $F = 0.9125$.\\\n",
    "The risk can be reduced by increasing the number of shots and/or the Pauli measurements performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: The Bell State and Randomized Pauli Measurement scheme\n",
    "\n",
    "Suppose that our target state $\\rho$ is the two-qubit Bell state\n",
    "\\begin{align}\n",
    "    \\rho &= \\vert \\psi \\rangle \\langle \\psi \\vert \\\\\n",
    "    \\text{where} \\quad \\vert \\psi \\rangle &= \\frac{1}{\\sqrt{2}} \\left(\\vert 00 \\rangle + \\vert 11 \\rangle\\right)\n",
    "\\end{align}\n",
    "\n",
    "Observe that $\\vert \\psi \\rangle$ is a stabilizer state that is generated by the stabilizers $XX$ and $ZZ$.\n",
    "\n",
    "To compute the fidelty, we use the minimax optimal measurement scheme for stabilizer states. This amounts to sampling uniformly from the stabilizer group elements (except the identity) and recording their measurement outcome ($\\pm 1).\n",
    "\n",
    "Let's compute the estimator given by the minimax method for such a setting.\n",
    "\n",
    "We know that\n",
    "\\begin{equation}\n",
    "    R = \\left\\lceil 2\\frac{\\ln\\left(2/\\epsilon\\right)}{\\left|\\ln\\left(1 - \\left(\\frac{d}{d - 1}\\right)^2 \\widehat{R}_*^2\\right)\\right|} \\right\\rceil\n",
    "\\end{equation}\n",
    "outcomes are sufficient to achieve a risk $\\widehat{\\mathcal{R}}_* \\in (0, 0.5)$ with a confidence level of $1 - \\epsilon \\in (0.75, 1)$.\n",
    "\n",
    "As before, we break down the process of constructing an estimator & computing an estimate into four steps:\n",
    "1. Create a YAML file describing the settings to construct the estimator and the risk.\n",
    "2. Construct the estimator for the specified settings.\n",
    "3. Store the outcomes in a YAML file. Convert outcomes to indices in case they are eigenvalues.\n",
    "4. Use the outcomes and constructed estimator to compute the fidelity estimate (and the risk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the YAML file containing the settings\n",
    "The YAML file looks as follows.\n",
    "\n",
    "### bell_state_settings.yml\n",
    "```\n",
    "target:\n",
    "    - stabilizer: [XX, ZZ]\n",
    "POVM_list:\n",
    "    - pauli: [RPM]\n",
    "R_list: 1657\n",
    "confidence_level: 0.95\n",
    "```\n",
    "\n",
    "We describe the a couple of above options in more detail:\n",
    "- The general syntax for specifying a target stabilizer state is `- stabilizer: list of stabilizer generators`. Note that we can include a sign in front of the Pauli operator if necessary.\\\n",
    "  For example, we specify a stabilizer state above with $XX$ and $ZZ$ as the stabilizer generators. We could as well have used $XX$ and $-YY$ as the stabilizer generators.\n",
    "- We have included a shortcut to specify the Randomized Pauli Measurement (RPM) scheme described in section II.E. of the PRA submission. The syntax is always `- pauli: [RPM]` for specifying this measurement scheme.\\\n",
    "  For stabilizer states, this amounts to randomly sampling the stabilizer group (excluding the identity) and recording the eigenvalues of outcomes.\n",
    "\n",
    "Note that we use a confidence level of $95\\%$ and a risk of $\\widehat{\\mathcal{R}}_* = 0.05$ to obtain $R = 1657$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Construct the estimator using the YAML settings file\n",
    "As before, we use the function ```construct_fidelity_estimator``` in ```handle_fidelity_estimation.py``` module to construct the estimator.\n",
    "\n",
    "We have placed `bell_state_settings.yaml` settings file in the `yaml_files` subdirectory.\n",
    "\n",
    "> The estimator for the RPM measurement scheme is constructed efficiently. It should take at most a few minutes, if not seconds, to construct the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization complete \n"
     ]
    }
   ],
   "source": [
    "import project_root # adds the root directory of the project to Python Path\n",
    "from handle_fidelity_estimation import construct_fidelity_estimator\n",
    "\n",
    "construct_fidelity_estimator(yaml_filename = 'bell_state_settings.yaml',\\\n",
    "                             estimator_filename = 'bell_state_estimator.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that there is a subdirectory called `estimator_files` (if it wasn't already there), and you can find the file `bell_state_estimator.json` there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a YAML file with the measurement outcomes\n",
    "\n",
    "We created some outcomes beforehand to test the estimator. For this purpose, we added $10\\%$ depolarizing noise to the target state $\\rho$, and then performed the Pauli measurements as prescibed by Randomized Pauli Measurement (RPM) scheme.\n",
    "\n",
    "Note that for the RPM scheme, only the *number* of $+1$ and $-1$ eigenvalues are important. It doesn't matter which Pauli measurement gave a $+1$ outcome or a $-1$ outcome.\\\n",
    "Before we supply the outcomes to the estimator, we need to convert $+1 \\to 0$ and $-1 \\to 1$. The reason is that the estimator works by referring to the POVM elements and we used $\\{E_+, E_-\\}$ as the POVM when constructing the estimator, in that order.\\\n",
    "Because the outcomes are going be just $0$ and $1$, we put the outcomes in a list inside a YAML file.\n",
    "\n",
    "> For the sake of demonstration, this time we choose to save our outcomes in a YAML file instead of a CSV file.\\\n",
    "  A CSV file can be used if that's preferred.\n",
    "\n",
    "The YAML file containing the outcomes looks as follows.\n",
    "### bell_state_measurement_outcomes.yaml\n",
    "```\n",
    "outcomes:\n",
    "    - [0, 0, ...]\n",
    "```\n",
    "Note that there must be exactly $R = 1657$ measurement outcomes, because the estimator was constructed for this case.\n",
    "\n",
    "> The syntax used in the YAML file is important for ensuring proper parsing of the file.\\\n",
    "  The code documentation can be referred for details.\n",
    "\n",
    "We use these outcomes to compute the fidelity estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compute the fidelity estimate\n",
    "We now supply the outcomes to the `compute_fidelity_estimate_risk` function in `handle_fidelity_estimation.py` module.\n",
    "\n",
    "We have saved the `bell_state_measurement_outcomes.yml` file in a subdirectory called `outcome_files`, and we use this to compute the estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity estimate: 0.933\n",
      "Risk: 0.05\n"
     ]
    }
   ],
   "source": [
    "import project_root # adds the root directory of the project to Python Path\n",
    "from handle_fidelity_estimation import compute_fidelity_estimate_risk\n",
    "\n",
    "compute_fidelity_estimate_risk(outcomes = './outcome_files/bell_state_measurement_outcomes.yaml',\\\n",
    "                               estimator_filename = 'bell_state_estimator.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the risk is very close to the value of $0.05$ (only a rounded value is displayed) that we chose to determine the number of outcomes $R = 1657$.\n",
    "\n",
    "We can also see that the fidelity estimate $\\widehat{F} \\approx 0.933$ is close to the actual fidelity $F = 0.925$, and within the specified risk of $0.05$.\n",
    "\n",
    "This estimate can be found in Table II of PRA submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epilogue\n",
    "\n",
    "Other formats are supported by the YAML settings file. You can directly supply lists to it or give a path to a `.npy` file which contains the array describing your target state or POVMs. Please read the documentation to see all the available options.\n",
    "\n",
    "Note that the code can be run directly from the commandline. This is especially helpful if one needs to run the code on a cluster or even on a workstation. Please refer the documentation for details on how to use this functionality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom_cvxpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e169b1ec56f5753475caf688589300511ee46247b3567ab21dc030f94e58219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

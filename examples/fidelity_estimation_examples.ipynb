{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fidelity estimation: Minimax Method\n",
    "We show how to use the code for minimax method using some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Cluster state and Pauli measurements\n",
    "To demonstrate how to use the minimax method to estimate fidelity, we consider a 3-qubit linear cluster state as our target state.\\\n",
    "We will focus on Pauli measurements.\n",
    "\n",
    "The minimax method constructs an estimator when the target state, the measurement settings, and the confidence level is specified. One we construct the estimator, we can repeatedly reuse the estimator for the chosen settings.\n",
    "\n",
    "We outline the basic steps that we will go through in this example - from specifying the settings to computing the estimate.\n",
    "1. Create a YAML file describing the settings required to construct the estimator.\n",
    "2. Construct the estimator using the specified settings.\n",
    "3. Create a CSV file containing the measurement outcomes.\n",
    "4. Compute the fidelity estimate using the CSV file and the constructed estimator.\n",
    "\n",
    "We remark that step 2 is usually computation intensive. Nevertheless, once the estimator has been constructed, the fidelity estimates (step 4) can be obtained almost instantaneously.\n",
    "\n",
    "Let's look at each step in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a YAML file with the measurement settings.\n",
    "[YAML](https://en.wikipedia.org/wiki/YAML) is a markup language that is human-readable, and can be parsed by a computer. The combination of these attributes makes it a good medium to specify the settings to the code.\n",
    "\n",
    "We allow for different ways to specify the settings in the YAML file.\\\n",
    "For example, one could specify the target state as a list in the YAML file, or provide a path to a `.npy` file containing the numpy array for the target state.\\\n",
    "Since Pauli measurements and some special states like the stabilizer states are commonly used, we have provided a special interface to conveniently specify these settings.\\\n",
    "We will be using the latter interface in this demo for convenience. For details on all available formats to specify the settings, we encourage the reader to refer to the documentation of the code.\n",
    "\n",
    "We create the following settings file for the cluster state. We specify those Pauli operators $P$ that have a non-zero weight $\\text{Tr}(P \\rho)$.\n",
    "\n",
    "-------------------------------------------------\n",
    "### cluster_state_settings.yaml\n",
    "```\n",
    "target:\n",
    "    - cluster: 3\n",
    "POVM_list:\n",
    "    - pauli: [IZX, XIX, XZI, YXY, YYZ, ZXZ, ZYY]\n",
    "R_list: 100\n",
    "confidence_level: 0.95\n",
    "algorithm: cvxpy\n",
    "```\n",
    "-------------------------------------------------\n",
    "\n",
    "Let's take a closer look at the settings.\n",
    "- `target` refers to the target state. We can conveniently provide a linear cluster state using the syntax: `- cluster: nq`, where `nq` is the number of qubits.\\\n",
    "  We have therefore specified a 3-qubit cluster state.\n",
    "  \n",
    "- `POVM_list` is a list of POVMs that will measured in order to estimate the fidelity.\\\n",
    "  Pauli measurements can be specified in a few different ways, but here we use the most obvious one: list the Pauli operators that you want to measure.\\\n",
    "  The default measurement is projection on each eigenvector of the Pauli operator, but if collective measurement on eigenspace with $+1$ and $-1$ eigenvalue is required, you can include the keyword `subspace` after listing all the Pauli operators.\n",
    "\n",
    "- `R_list` corresponds to the number of outcomes recorded for each POVM.\\\n",
    "    We want 100 outcomes for each Pauli measurement, so we simply write 100.\\\n",
    "    If something more specific is required, write a list of outcomes, one for each Pauli measurement.\n",
    "\n",
    "- `confidence_level` should be a number between 0.75 and 1, and it determines the confidence level of the computed risk.\n",
    "\n",
    "- `algorithm` should be either `saddle_point` (default) or `cvxpy`.\\\n",
    "  `saddle_point` implements accelerated projected gradient descent, which is slower than `cvxpy` but can handle higher dimensional matrices.\\\n",
    "    For demonstration, we choose the `cvxpy` algorithm for this example, as it runs faster.\n",
    "----------\n",
    "> **It is important to adhere to the syntax specified in the documentation when creating the YAML file.**\\\n",
    "The code is expected to throw an error when incorrect syntax is used. However, there could be some cases that slip past the sanity checks, and the code may end up constructing an estimator that was not intended by the user!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Construct the estimator\n",
    "In order to construct the estimator, we use the function ```construct_fidelity_estimator``` included in ```handle_fidelity_estimation.py``` module.\n",
    "\n",
    "The syntax for this function is pretty straightforward:\n",
    "\n",
    "----------------------\n",
    "```\n",
    "construct_fidelity_estimator(yaml_filename, estimator_filename,\n",
    "                             yaml_file_dir = './yaml_files', estimator_dir = './estimator_files')\n",
    "```\n",
    "----------------------\n",
    "\n",
    "A closer look at the options:\n",
    "- ```yaml_filename``` refers to the name of the YAML settings file.\n",
    "- ```estimator_filename``` refers to the name of the (JSON) file to which the constructed estimator is saved.\n",
    "- ```yaml_file_dir``` specifies the directory in which the YAML settings file is stored.\\\n",
    "  This is an optional argument, and if nothing is specified, the code assumes that the YAML file lives in a sub-directory named `yaml_files` of the current directory.\n",
    "- ```estimator_dir``` specifies the directory where the constructed estimator is saved.\\\n",
    "  As before, this is an optional argument, and the default location is assumed to be a sub-directory named `estimator_files` of the current directory.\n",
    "\n",
    "------------------\n",
    "\n",
    "> We save the estimator because the same estimator can be re-used later for the same settings.\\\n",
    "The estimator is saved as a JSON file. These files are internally handled by the functions in the module, and need not be edited manually by the user.\n",
    "\n",
    "------------------\n",
    "\n",
    "Following the default options, we have created a subdirectory called `yaml_files` and placed `cluster_state_settings.yaml` YAML file there. Let us now construct the estimator. \n",
    "\n",
    "> **It can take anywhere from a few minutes to many hours to compute the estimator depending on the settings that were specified.**\\\n",
    "  If the dimension of the system is large or many measurement settings are begin used, please consider running the code on a workstation or a cluster.\n",
    "  \n",
    "The following code is expected to run in about 4 minutes on a laptop, though the actual time may vary depending on the hardware and the OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.2.1                                    \n",
      "===============================================================================\n",
      "(CVXPY) Jun 05 09:29:51 PM: Your problem has 128 variables, 5 constraints, and 0 parameters.\n",
      "(CVXPY) Jun 05 09:29:51 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Jun 05 09:29:51 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Jun 05 09:29:51 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jun 05 09:29:51 PM: Compiling problem (target solver=SCS).\n",
      "(CVXPY) Jun 05 09:29:51 PM: Reduction chain: Complex2Real -> FlipObjective -> Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCS\n",
      "(CVXPY) Jun 05 09:29:51 PM: Applying reduction Complex2Real\n",
      "(CVXPY) Jun 05 09:29:51 PM: Applying reduction FlipObjective\n",
      "(CVXPY) Jun 05 09:29:51 PM: Applying reduction Dcp2Cone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/Work/Projects/Quantum_Information/Fidelity_Estimation/Github/minimax-fidelity-estimation/handle_fidelity_estimation.py:453: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if POVM_list[0][0] == \"rpm\":\n",
      "/home/akshay/Work/Projects/Quantum_Information/Fidelity_Estimation/Github/minimax-fidelity-estimation/src/fidelity_estimation_cvxpy.py:148: UserWarning: The initial condition for the necessary CVXPY solvers are fixed. The `random_init` parameter will be unused.\n",
      "  warnings.warn(\"The initial condition for the necessary CVXPY solvers are fixed. The `random_init` parameter will be unused.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Jun 05 09:29:51 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Jun 05 09:29:51 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) Jun 05 09:29:52 PM: Applying reduction SCS\n",
      "(CVXPY) Jun 05 09:29:52 PM: Finished problem compilation (took 7.281e-01 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jun 05 09:29:52 PM: Invoking solver SCS  to obtain a solution.\n",
      "------------------------------------------------------------------\n",
      "\t       SCS v3.2.0 - Splitting Conic Solver\n",
      "\t(c) Brendan O'Donoghue, Stanford University, 2012\n",
      "------------------------------------------------------------------\n",
      "problem:  variables n: 263, constraints m: 466\n",
      "cones: \t  z: primal zero / dual free vars: 4\n",
      "\t  l: linear vars: 1\n",
      "\t  q: soc vars: 168, qsize: 56\n",
      "\t  s: psd vars: 272, ssize: 2\n",
      "\t  e: exp vars: 21, dual exp vars: 0\n",
      "settings: eps_abs: 0.0e+00, eps_rel: 1.0e-06, eps_infeas: 1.0e-07\n",
      "\t  alpha: 1.50, scale: 1.00e-01, adaptive_scale: 1\n",
      "\t  max_iters: 100000, normalize: 1, rho_x: 1.00e-06\n",
      "\t  acceleration_lookback: 10, acceleration_interval: 10\n",
      "lin-sys:  sparse-direct\n",
      "\t  nnz(A): 3678, nnz(P): 0\n",
      "------------------------------------------------------------------\n",
      " iter | pri res | dua res |   gap   |   obj   |  scale  | time (s)\n",
      "------------------------------------------------------------------\n",
      "     0| 3.69e+00  3.97e-01  5.16e+00 -1.15e+00  1.00e-01  4.94e-04 \n",
      "   250| 3.31e-03  3.92e-04  3.55e-02 -1.19e-01  1.00e-01  3.87e-02 \n",
      "   500| 7.35e-05  7.60e-06  6.76e-04 -8.64e-02  1.00e-01  7.50e-02 \n",
      "   650| 2.66e-07  3.90e-09  3.02e-08 -8.60e-02  1.00e-01  9.69e-02 \n",
      "------------------------------------------------------------------\n",
      "status:  solved\n",
      "timings: total: 9.95e-02s = setup: 2.65e-03s + solve: 9.69e-02s\n",
      "\t lin-sys: 1.35e-02s, cones: 7.75e-02s, accel: 9.54e-04s\n",
      "------------------------------------------------------------------\n",
      "objective = -0.085954\n",
      "------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Jun 05 09:29:52 PM: Problem status: optimal\n",
      "(CVXPY) Jun 05 09:29:52 PM: Optimal value: 8.595e-02\n",
      "(CVXPY) Jun 05 09:29:52 PM: Compilation took 7.281e-01 seconds\n",
      "(CVXPY) Jun 05 09:29:52 PM: Solver (including time spent in interface) took 1.004e-01 seconds\n"
     ]
    }
   ],
   "source": [
    "import project_root # adds the root directory of the project to Python Path\n",
    "from handle_fidelity_estimation import construct_fidelity_estimator\n",
    "\n",
    "construct_fidelity_estimator(yaml_filename = 'cluster_state_settings.yaml',\\\n",
    "                             estimator_filename = 'cluster_state_estimator.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Note that `construct_fidelity_estimator` prints the progress of optimization by default.\\\n",
    "     If you wish to turn this off, supply `print_progress = False` as an additional argument to the function.\n",
    "2. If an estimator file already exists, `construct_fidelity_estimator` function will throw an error. You can delete the existing estimator, move it to a different directory, or use another name to save the estimator in that case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate measurement outcomes\n",
    "We generate the measurement outcomes separately and store them in a CSV file.\\\n",
    "Note that these outcomes are generated using the state obtained by applying 10% depolarizing noise to the target state.\n",
    "\n",
    "> In practice, these outcomes will come from experiments.\n",
    "\n",
    "The CSV file looks as follows:\n",
    "\n",
    "---------------------\n",
    "### cluster_state_outcomes.csv\n",
    "\n",
    "|     |   |   |     |   |\n",
    "| --- | - | - | --- | - |\n",
    "| IZX | 7 | 0 | ... | 7 |\n",
    "| XIX | 7 | 7 | ... | 0 |\n",
    "|  .  | . | . |  .  | . |\n",
    "| ZYY | 5 | 3 | ... | 0 |\n",
    "\n",
    "---------------------\n",
    "The first column contains the labels of the Pauli measurements performed.\\\n",
    "Corresponding to each Pauli operator, we store the measurement outcomes in the same row as the Pauli operator.\\\n",
    "Outcome $i$ points to the eigenvector $\\vert i \\rangle$ that was observed upon measurement.\n",
    "\n",
    "> 1. **It is important that the order of eigenvectors used for outcomes matches the POVM that was specified for constructing the estimator.**\\\n",
    "  We use the following convention for the eigenvectors: $\\vert+++\\rangle$, $\\vert++-\\rangle$, $\\vert+-+\\rangle$, ..., $\\vert---\\rangle$.\\\n",
    "  Basically, we use the binary expansion of numbers from $0$ to $2^{n_q} - 1$, where $n_q$ are the number of qubits, with $0$ replaced by $+$ and $1$ replaced by $-$.\n",
    "2. **It is important that the outcomes for Pauli operators are listed in the same order as what we used for constructing the estimator.**\\\n",
    "   That is, we must have outcomes for IZXZ, XIX, ..., ZYY in that order in the CSV file.\n",
    "  \n",
    "Note for any Pauli operator $P = X_1 \\dotsb X_{n_q}$, a $+$ at the $i$th qubit location means that we are looking at the $+1$ eigenvector of $X_i$, where $X_i \\in \\{I, X, Y, Z\\}$.\n",
    "\n",
    "> In practice, steps 2 & 3 can occur in any order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compute the fidelity estimate\n",
    "Let's use the estimator that we constructed in step 2 and the outcomes generated in step 3 to compute the fidelity estimate.\\\n",
    "This task is handled by `compute_fidelity_estimate_risk` function in `handle_fidelity_estimation.py` module.\n",
    "\n",
    "This function takes the following form.\n",
    "\n",
    "----------------\n",
    "```\n",
    "compute_fidelity_estimate_risk(outcomes, estimator_filename, estimator_dir = './estimator_files')\n",
    "```\n",
    "----------------\n",
    "\n",
    "The options accept the following formats:\n",
    "- `outcomes` can be one of the following:\n",
    "    1. A list of outcomes for each POVM measurement.\n",
    "    2. Path to a YAML file containing a list of outcomes for each POVM measurement.\n",
    "    3. - Path to a CSV file, or\n",
    "       - A dictionary:\\\n",
    "           `{'csv_file_path': Path to CSV file, 'entries': 'row'/'column', 'start': (row index, column index)}`\\\n",
    "         where `row` (`column`) is used if data is stored in rows (columns),\\\n",
    "         and `start` denotes the index of the cell where the data starts (we start the row and column at index 0).\n",
    "- `estimator_filename` is the name of the estimator file that we constructed previously.\n",
    "- `estimator_dir` refers to the directory in which the estimator file has been saved.\n",
    "\n",
    "We refer the reader to the documentation of the code which elaborates these options further.\n",
    "\n",
    "As we can see from the CSV file outline in step 3, the data starts at the first row and the second column.\\\n",
    "The first column describes the data, but is not actually a part of it. Therefore, we set `start = (0, 1)`.\\\n",
    "As noted earlier, we label the rows and columns starting from 0, following Python convention.\\\n",
    "Also, it is clear that the data is stored row-wise, so we set `entries = 'row'`.\n",
    "\n",
    "Note that we have saved the `cluster_state_outcomes.csv` file in a subdirectory called `outcome_files`.\\\n",
    "Using this, we compute the estimate as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity estimate: 0.91\n",
      "Risk: 0.086\n"
     ]
    }
   ],
   "source": [
    "import project_root # adds the root directory of the project to Python Path\n",
    "from handle_fidelity_estimation import compute_fidelity_estimate_risk\n",
    "\n",
    "compute_fidelity_estimate_risk(outcomes = {'csv_file_path': './outcome_files/cluster_state_outcomes.csv',\\\n",
    "                                           'entries': 'row', 'start': (0, 1)},\\\n",
    "                               estimator_filename = 'cluster_state_estimator.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the estimate $\\widehat{F} \\approx 0.91$ is close to the actual fidelity $F = 0.9125$.\\\n",
    "The risk can be reduced by increasing the number of shots and/or the Pauli measurements performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: The Bell State and Randomized Pauli Measurement scheme\n",
    "\n",
    "Suppose that our target state $\\rho$ is the two-qubit Bell state\n",
    "\\begin{align}\n",
    "    \\rho &= \\vert \\psi \\rangle \\langle \\psi \\vert \\\\\n",
    "    \\text{where} \\quad \\vert \\psi \\rangle &= \\frac{1}{\\sqrt{2}} \\left(\\vert 00 \\rangle + \\vert 11 \\rangle\\right)\n",
    "\\end{align}\n",
    "\n",
    "Observe that $\\vert \\psi \\rangle$ is a stabilizer state that is generated by the stabilizers $XX$ and $ZZ$.\n",
    "\n",
    "To compute the fidelty, we use the minimax optimal measurement scheme for stabilizer states. This amounts to sampling uniformly from the stabilizer group elements (except the identity) and recording their measurement outcome ($\\pm 1).\n",
    "\n",
    "Let's compute the estimator given by the minimax method for such a setting.\n",
    "\n",
    "We know that\n",
    "\\begin{equation}\n",
    "    R = \\left\\lceil 2\\frac{\\ln\\left(2/\\epsilon\\right)}{\\left|\\ln\\left(1 - \\left(\\frac{d}{d - 1}\\right)^2 \\widehat{R}_*^2\\right)\\right|} \\right\\rceil\n",
    "\\end{equation}\n",
    "outcomes are sufficient to achieve a risk $\\widehat{\\mathcal{R}}_* \\in (0, 0.5)$ with a confidence level of $1 - \\epsilon \\in (0.75, 1)$.\n",
    "\n",
    "As before, we break down the process of constructing an estimator & computing an estimate into four steps:\n",
    "1. Create a YAML file describing the settings to construct the estimator and the risk.\n",
    "2. Construct the estimator for the specified settings.\n",
    "3. Store the outcomes in a YAML file. Convert outcomes to indices in case they are eigenvalues.\n",
    "4. Use the outcomes and constructed estimator to compute the fidelity estimate (and the risk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the YAML file containing the settings\n",
    "The YAML file looks as follows.\n",
    "\n",
    "### bell_state_settings.yml\n",
    "```\n",
    "target:\n",
    "    - stabilizer: [XX, ZZ]\n",
    "POVM_list:\n",
    "    - pauli: [RPM]\n",
    "R_list: 1657\n",
    "confidence_level: 0.95\n",
    "```\n",
    "\n",
    "We describe the a couple of above options in more detail:\n",
    "- The general syntax for specifying a target stabilizer state is `- stabilizer: list of stabilizer generators`. Note that we can include a sign in front of the Pauli operator if necessary.\\\n",
    "  For example, we specify a stabilizer state above with $XX$ and $ZZ$ as the stabilizer generators. We could as well have used $XX$ and $-YY$ as the stabilizer generators.\n",
    "- We have included a shortcut to specify the Randomized Pauli Measurement (RPM) scheme described in section II.E. of the PRA submission. The syntax is always `- pauli: [RPM]` for specifying this measurement scheme.\\\n",
    "  For stabilizer states, this amounts to randomly sampling the stabilizer group (excluding the identity) and recording the eigenvalues of outcomes.\n",
    "\n",
    "Note that we use a confidence level of $95\\%$ and a risk of $\\widehat{\\mathcal{R}}_* = 0.05$ to obtain $R = 1657$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Construct the estimator using the YAML settings file\n",
    "As before, we use the function ```construct_fidelity_estimator``` in ```handle_fidelity_estimation.py``` module to construct the estimator.\n",
    "\n",
    "We have placed `bell_state_settings.yaml` settings file in the `yaml_files` subdirectory.\n",
    "\n",
    "> The estimator for the RPM measurement scheme is constructed efficiently. It should take at most a few minutes, if not seconds, to construct the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization complete \n"
     ]
    }
   ],
   "source": [
    "import project_root # adds the root directory of the project to Python Path\n",
    "from handle_fidelity_estimation import construct_fidelity_estimator\n",
    "\n",
    "construct_fidelity_estimator(yaml_filename = 'bell_state_settings.yaml',\\\n",
    "                             estimator_filename = 'bell_state_estimator.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that there is a subdirectory called `estimator_files` (if it wasn't already there), and you can find the file `bell_state_estimator.json` there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a YAML file with the measurement outcomes\n",
    "\n",
    "We created some outcomes beforehand to test the estimator. For this purpose, we added $10\\%$ depolarizing noise to the target state $\\rho$, and then performed the Pauli measurements as prescibed by Randomized Pauli Measurement (RPM) scheme.\n",
    "\n",
    "Note that for the RPM scheme, only the *number* of $+1$ and $-1$ eigenvalues are important. It doesn't matter which Pauli measurement gave a $+1$ outcome or a $-1$ outcome.\\\n",
    "Before we supply the outcomes to the estimator, we need to convert $+1 \\to 0$ and $-1 \\to 1$. The reason is that the estimator works by referring to the POVM elements and we used $\\{E_+, E_-\\}$ as the POVM when constructing the estimator, in that order.\\\n",
    "Because the outcomes are going be just $0$ and $1$, we put the outcomes in a list inside a YAML file.\n",
    "\n",
    "> For the sake of demonstration, this time we choose to save our outcomes in a YAML file instead of a CSV file.\\\n",
    "  A CSV file can be used if that's preferred.\n",
    "\n",
    "The YAML file containing the outcomes looks as follows.\n",
    "### bell_state_measurement_outcomes.yaml\n",
    "```\n",
    "outcomes:\n",
    "    - [0, 0, ...]\n",
    "```\n",
    "Note that there must be exactly $R = 1657$ measurement outcomes, because the estimator was constructed for this case.\n",
    "\n",
    "> The syntax used in the YAML file is important for ensuring proper parsing of the file.\\\n",
    "  The code documentation can be referred for details.\n",
    "\n",
    "We use these outcomes to compute the fidelity estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compute the fidelity estimate\n",
    "We now supply the outcomes to the `compute_fidelity_estimate_risk` function in `handle_fidelity_estimation.py` module.\n",
    "\n",
    "We have saved the `bell_state_measurement_outcomes.yml` file in a subdirectory called `outcome_files`, and we use this to compute the estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity estimate: 0.933\n",
      "Risk: 0.05\n"
     ]
    }
   ],
   "source": [
    "import project_root # adds the root directory of the project to Python Path\n",
    "from handle_fidelity_estimation import compute_fidelity_estimate_risk\n",
    "\n",
    "compute_fidelity_estimate_risk(outcomes = './outcome_files/bell_state_measurement_outcomes.yaml',\\\n",
    "                               estimator_filename = 'bell_state_estimator.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the risk is very close to the value of $0.05$ (only a rounded value is displayed) that we chose to determine the number of outcomes $R = 1657$.\n",
    "\n",
    "We can also see that the fidelity estimate $\\widehat{F} \\approx 0.933$ is close to the actual fidelity $F = 0.925$, and within the specified risk of $0.05$.\n",
    "\n",
    "This estimate can be found in Table II of PRA submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epilogue\n",
    "\n",
    "Other formats are supported by the YAML settings file. You can directly supply lists to it or give a path to a `.npy` file which contains the array describing your target state or POVMs. Please read the documentation to see all the available options.\n",
    "\n",
    "Note that the code can be run directly from the commandline. This is especially helpful if one needs to run the code on a cluster or even on a workstation. Please refer the documentation for details on how to use this functionality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e169b1ec56f5753475caf688589300511ee46247b3567ab21dc030f94e58219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
